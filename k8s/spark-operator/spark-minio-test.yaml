apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-minio-test
spec:
  type: Python
  mode: cluster
  image: "hyeondata/spark-py-aws:3.5.7-v1"
  mainApplicationFile: "local:///opt/spark/work-dir/minio-test.py"
  sparkVersion: "3.5.7"
  sparkConf:
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.endpoint": "http://192.168.0.14:9000"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "com.amazonaws.auth.EnvironmentVariableCredentialsProvider"
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "s3a://spark-logs"
  driver:
    cores: 1
    memory: "512m"
    serviceAccount: spark-sa
    volumeMounts:
      - name: "test-script"
        mountPath: "/opt/spark/work-dir"
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom: { secretKeyRef: { name: minio-s3-keys, key: access-key } }
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom: { secretKeyRef: { name: minio-s3-keys, key: secret-key } }
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom: { secretKeyRef: { name: minio-s3-keys, key: access-key } }
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom: { secretKeyRef: { name: minio-s3-keys, key: secret-key } }
  volumes:
    - name: "test-script"
      configMap:
        name: spark-test-script