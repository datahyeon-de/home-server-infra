apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-minio-test
  namespace: default
spec:
  type: Python
  mode: cluster
  image: "hyeondata/spark-py-aws:3.5.7-v1" # 본인의 이미지명
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "local:///opt/spark/work-dir/minio-test.py"
  sparkVersion: "3.5.7"
  restartPolicy:
    type: Never
  sparkConf:
    # 1. S3Guard 기능을 완전히 뿌리뽑는 3종 세트
    "spark.hadoop.fs.s3a.metadatastore.impl": "org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore"
    "spark.hadoop.fs.s3a.s3guard.index.enabled": "false"
    "fs.s3a.metadatastore.impl": "org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore"

    # 2. 인증 및 엔드포인트 설정 (Provider 유지)
    "spark.hadoop.fs.s3a.aws.credentials.provider": "com.amazonaws.auth.EnvironmentVariableCredentialsProvider"
    "spark.hadoop.fs.s3a.endpoint": "http://192.168.0.14:9000"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.endpoint.region": "ap-northeast-2"
    "spark.hadoop.fs.s3a.connection.ssl.enabled": "false"

    # 3. 로그 설정 (슬래시 제외)
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "s3a://spark-logs"
    "spark.yarn.historyServer.address": "http://spark-history-server:18080"

  driver:
    cores: 1
    memory: "512m"
    labels:
      version: 3.5.7
    serviceAccount: spark-sa
    # 시크릿을 환경변수로 주입 (선택 사항)
    envFrom:
      - secretRef:
          name: minio-s3-keys
    # ConfigMap 마운트
    volumeMounts:
      - name: "test-script"
        mountPath: "/opt/spark/work-dir"
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: minio-s3-keys
            key: access-key
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: minio-s3-keys
            key: secret-key
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: minio-s3-keys
            key: endpoint
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: minio-s3-keys
            key: access-key
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: minio-s3-keys
            key: secret-key
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: minio-s3-keys
            key: endpoint
    envFrom:
      - secretRef:
          name: minio-s3-keys
  volumes:
    - name: "test-script"
      configMap:
        name: spark-test-script
